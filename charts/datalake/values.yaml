jenkins:
  replicaCount: 1
  image:
    repository: art-hq.intranet.qualys.com:5001/datalake/jenkins
    tag: 0.1.1
    pullPolicy: IfNotPresent
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/rewrite-target: /
      kubernetes.io/app-root: /jenkins
    path: /
    hosts:
      - jenkinsd
  service:
    type: ClusterIP
    ui: 8080
  resources:
    requests:
      cpu: 100m
  nodeSelector: {}
  tolerations: []
  affinity: {}

zeppelin:
  namespace: default
  replicaCount: 1
  image:
    repository: art-hq.intranet.qualys.com:5001/datalake/zeppelin
    tag: 0.2.9
    pullPolicy: IfNotPresent
  service:
    type: NodePort
    port: 8080
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/rewrite-target: /
      kubernetes.io/app-root: /zeppelin
    path: /
    hosts:
      - zeppelin
  resources:
    requests:
      cpu: 100m
  nodeSelector: {}
  tolerations: []
  affinity: {}

alluxio:
  namespace: default
  replicaCount: 1
  image:
    repository: art-hq.intranet.qualys.com:5001/datalake/alluxio
    tag: 0.1.2
    pullPolicy: IfNotPresent
  service:
    type: None
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/rewrite-target: /
      kubernetes.io/app-root: /alluxio
    path: /
    hosts:
      - alluxio
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  hostUnderfs: /mnt
  hostShortCircuit: /tmp/domain

hiveservice:
  replicaCount: 1
  image:
    repository: art-hq.intranet.qualys.com:5001/datalake/hiveservice
    tag: 0.3.3
    pullPolicy: IfNotPresent
  ingress:
    enabled: false
  service:
    type: ClusterIP
    portThrift: 9083
  resources:
    requests:
      cpu: 100m
  nodeSelector: {}
  tolerations: []
  affinity: {}

spark:
  spark_master:
    replicaCount: 1
  spark_worker:
    replicaCount: 1
  image:
    spark:
      repository: art-hq.intranet.qualys.com:5001/datalake/spark
      tag: 0.3.1
      pullPolicy: IfNotPresent
    proxy:
      repository: art-hq.intranet.qualys.com:5001/datalake/spark-ui-proxy
      tag: "1.0"
      pullPolicy: IfNotPresent
  ingress:
    enabled: false
  service:
    spark:
      type: None
      portUI: 8080
      portRPC: 7077
    proxy:
      type: NodePort
      port: 80
      nodePortUI: 30006
  resources:
    requests:
      cpu: 100m
  nodeSelector: {}
  tolerations: []
  affinity: {}

spark-hadoop:
  spark_master:
    replicaCount: 1
  spark_worker:
    replicaCount: 1
  image:
    spark:
      repository: art-hq.intranet.qualys.com:5001/datalake/spark-hadoop
      tag: 0.3.1
      pullPolicy: IfNotPresent
    proxy:
      repository: art-hq.intranet.qualys.com:5001/datalake/spark-ui-proxy
      tag: "1.0"
      pullPolicy: IfNotPresent
  ingress:
    enabled: false
  service:
    spark:
      type: None
      portUI: 8080
      portRPC: 7077
    proxy:
      type: NodePort
      port: 80
      nodePortUI: 30007
  resources:
    requests:
      cpu: 100m
  nodeSelector: {}
  tolerations: []
  affinity: {}

hiveserver:
  replicaCount: 1
  image:
    repository: art-hq.intranet.qualys.com:5001/datalake/hiveserver
    tag: 0.3.0
    pullPolicy: IfNotPresent
  service:
    type: None
    portHTTP: 10001
    portUI: 10002
    nodePortUI: 30004
    nodePortHTTP: 30005
  ingress:
    enabled: false
  resources:
    requests:
      cpu: 100m
  nodeSelector: {}
  tolerations: []
  affinity: {}

postgresql:
  image: "art-hq.intranet.qualys.com:5001/datalake/postgres"
  imageTag: "9.6.9-hive-3.1.0"
  postgresUser: hive
  pullPolicy: IfNotPresent
  ## Default: random 10 character string
  postgresPassword: hive
  ## Inject postgresPassword via a volume mount instead of environment variable
  usePasswordFile: false
  ## Use Existing secret instead of creating one
  ## It must have a postgres-password key containing the desired password
  # existingSecret: 'secret'

  ## Default: the postgres user
  postgresDatabase: metastore
  persistence:
    enabled: true

    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    existingClaim: postgres-pv-claim

    ## database data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass: "-"
    accessMode: ReadWriteOnce
    size: 8Gi
    subPath: "postgresql-db"
    mountPath: /var/lib/postgresql/data/pgdata
  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources:
    requests:
      memory: 256Mi
      cpu: 100m

  service:
    type: ClusterIP
    port: 5432
    externalIPs: []
    ## Manually set NodePort value
    ## Requires service.type: NodePort
    # nodePort:

  networkPolicy:
    ## Enable creation of NetworkPolicy resources.
    ##
    enabled: false
    ## The Policy model to apply. When set to false, only pods with the correct
    ## client label will have network access to the port PostgreSQL is listening
    ## on. When true, PostgreSQL will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true

  ## Node labels and tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature
  nodeSelector: {}
  tolerations: []
  affinity: {}

  # Override default liveness & readiness probes
  probes:
    liveness:
      initialDelay: 60
      timeoutSeconds: 5
      failureThreshold: 6
    readiness:
      initialDelay: 5
      timeoutSeconds: 3
      periodSeconds: 5
  ## Annotations for the deployment and nodes.
  deploymentAnnotations: {}
  podAnnotations: {}

  ## Deployment pods replace strategy
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  # strategy: {}
prometheus-operator:
  global:
    # Hyperkube image to use when getting ThirdPartyResources & cleaning up
    hyperkube:
      repository: art-hq.intranet.qualys.com:5001/datalake/hyperkube
      tag: v1.10.4_coreos.0
      pullPolicy: IfNotPresent
  
  # Prometheus-config-reloader image to use for config and rule reloading
  prometheusConfigReloader:
    repository: art-hq.intranet.qualys.com:5001/datalake/prometheus-config-reloader
    tag: v0.23.2
  
  # Configmap-reload image to use for reloading configmaps
  configmapReload:
    repository: art-hq.intranet.qualys.com:5001/datalake/configmap-reload
    tag: v0.0.1
  
  # Prometheus-operator image
  image:
    repository: art-hq.intranet.qualys.com:5001/datalake/prometheus-operator
    tag: v0.23.2
    pullPolicy: IfNotPresent
  
  # If enabled, prometheus-operator will create a service for scraping kubelets
  kubeletService:
    enable: true
    namespace: kube-system
    name: kubelet
  
  nodeSelector: {}
  tolerations: {}
  
  # If true, create & use RBAC resources
  rbacEnable: true
  
  # If true, create Pod Security Policy resources
  pspEnable: true
  
  # Reference to one or more secrets to be used when pulling images
  imagePullSecrets: []
  #  - name: "image-pull-secret"
  
  # Use logfmt (default) or json-formatted logging
  # logFormat: logfmt
  
  resources:
    limits:
      cpu: 200m
      memory: 100Mi
    requests:
      cpu: 100m
      memory: 50Mi
  
  jobLabel: prometheus-operator
