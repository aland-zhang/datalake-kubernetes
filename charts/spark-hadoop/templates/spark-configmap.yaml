apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "datalake.spark-hadoop-master.fullname" . }}
  labels:
    app: {{ template "datalake.spark-hadoop-master.name" . }}
    chart: {{ template "datalake.subchart" . }}
    release: {{ .Release.Name }}
data:
  spark-defaults.conf: |
    spark.master spark://spark-hadoop-master:7077
    spark.app.id QualysSpark
    spark.hadoop.datanucleus.autoCreateSchema false
    spark.executor.memory 8g
    spark.executor.memoryOverhead   384m
    spark.driver.memory 4g
    spark.driver.memoryOverhead  384m
    spark.scheduler.minRegisteredResourcesRatio 0.8
    spark.sql.hive.metastore.version 3.1.0
    spark.sql.hive.metastore.schema.verification false

  hive-site.xml: |
    <configuration>
      <property>
        <name>hive.metastore.uris</name>
        <value>thrift://hiveservice:9083</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
      </property>
      <property>
        <name>hive.execution.engine</name>
        <value>spark</value>
      </property>
      <property>
        <name>spark.home</name>
        <value>/opt/spark</value>
      </property>
      <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>false</value>
      </property>
      <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
      </property>
      <property>
        <name>datanucleus.schema.autoCreateAll</name>
        <value>false</value>
      </property>
      <property>
        <name>datanucleus.fixedDatastore</name>
        <value>true</value>
      </property>
      <property>
      <property>
        <name>spark.master</name>
        <value>spark://spark-hadoop-master:6066</value>
      </property>
        <name>spark.executor.memory</name>
        <value>7g</value>
      </property>
      <property>
        <name>spark.driver.memory</name>
        <value>1g</value>
      </property>
      <property>
        <name>spark.executor.memoryOverhead</name>
        <value>384m</value>
      </property>
      <property>
        <name>spark.driver.memoryOverhead</name>
        <value>384m</value>
      </property>
      <property>
        <name>spark.scheduler.minRegisteredResourcesRatio</name>
        <value>0.8</value>
      </property>

      <property>
        <name>fs.defaultFS</name>
        <value>s3a://qlake</value>
      </property>
      <property>
        <name>fs.s3a.impl</name>
        <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
      </property>
      <property>
        <name>fs.AbstractFileSystem.s3a.impl</name>
        <value>org.apache.hadoop.fs.s3a.S3A</value>
      </property>
      <property>
        <name>fs.s3a.path.style.access</name>
        <value>true</value>
      </property>
      <property>
        <name>fs.s3a.connection.ssl.enabled</name>
        <value>false</value>
      </property>
      <property>
        <name>fs.s3a.endpoint</name>
        <value>http://minio.p02.eng.sjc01.qualys.com</value>
      </property>
      <property>
        <name>sPath</name>
        <value>/qlake</value>
      </property>
      <property>
        <name>fs.s3a.access.key</name>
        <value>AKIAIOSFODNN7EXAMPLE</value>
      </property>
      <property>
        <name>fs.s3a.secret.key</name>
        <value>wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</value>
      </property>
    </configuration>